{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dcb9d7",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2679669346.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mgcloud auth login\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acaa1d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ade8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: dev-tradyon-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"dev-tradyon-data\"\n",
    "print(\"Using project:\", os.environ[\"GOOGLE_CLOUD_PROJECT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2b94f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample row: {'product_id': 'p30', 'product_name': 'Bulk Commodity Green Coffee', 'synonymns': '', 'product_schema': {'Certifications': ['Organic', 'Rainforest Alliance', '4C', 'Cafe Practices', 'BASC', 'Fairtrade', 'Fairtrade USA', 'IP', 'Mayacert', 'NOP', 'EUDR', 'Fairtrade Usa, Organic', 'JAS Organic', 'Flo, Fairtrade, Organic', 'FLO', 'Organic, Mayacert', 'Fair Trade Usa, Organic', 'Organic, Nop', 'NOP, Rainforest Alliance Certified', 'Fairtrade, NOP Organic', 'NOP Organic', 'Fairtrade, Organic', 'Fairtrade, Nop, Organic, Rainforest Alliance Certified', 'Fairtrade, Nop, Organic', 'Fair Trade Organic', 'Fair Trade, Organic', 'EOS Certified', 'Rainforest Alliance, Organic', 'Mayacert, Nop', 'Fair Trade Usa, Organic, Cor', 'Fairtrade, Flo, Organic', 'Fair Trade Usa, Organic, Mayacert', 'Fairtrade, Flo Certified, Organic, Mayacert'], 'Coffee_Variety': ['Robusta', 'Arabica', 'Excelsa', 'Bourbon', 'Caturra', 'Caturra-Catimor', 'Liberica'], 'Defect_Percentage': ['15 Defects', '1,5%', '15', '12 Defects', '80 Defects', '120 Defects Per 60 Grams', '2% BBB', '2 PCT BLACK AND BROKEN, 1 PCT FOREIGN MATTER', 'Max 12.5 Pct', '0.1 PCT', '0.1PCT', '90 Defects', '600 DEF', '1.5%', '800 Defects', 'Max 12 Def In 300gr', '18 Defects', 'Max 90 Def', '23', '180 Defects', '250 Defects', '350 Defects', 'Max 120 Def', '80DEF', '10%', '5%bb', '25% broken black', '18 DEF', '40', '15 DEFS', 'Less Than 12 Defects Per 100 Grams', 'Max 45 defects', 'Max 23 Def In 300gr', 'Max 180 Def', '12 DEF', '50 DEF', '18', '5%', '180 Def', '28 Defects', '120 Defects Per 100 Grams', '03% Broken', '5% Bb', '25%', '5-10 Def', '120 Defects', '120', '8 DEF', '5% Black', '2%', 'MAX 80 DEFECTS', 'MAX 150 DEF', 'ZERO DEFECT', '2% Black Broken', '135% Black Broken', '3% Black', '5% Black Broken', '25% Black', '01% Black, 01% Brown, 01% FM, 03% Broken', '3% Impurities', '7% Impurities', '2% broken black', '2% Broken', '3% Broken Black', '5% Broken Black', '35% broken black', '03%', '35%', '2% BB'], 'Origin_Country': ['Indonesia', 'Tanzania', 'Nicaragua', 'Honduras', 'Brazil', 'Uganda', 'Australia', 'Papua New Guinea', 'Vietnam', 'Colombia', 'Costa Rica', 'Mexico', 'Peru', 'Kenya', 'India', 'Mozambique', 'Jamaica', 'Ethiopia', 'El Salvador', 'Burundi', 'Lao', 'Guatemala', 'Dominican Republic', 'Bolivia', 'Panama', 'United States', 'Rwanda', 'China', 'Yemen', 'Switzerland', 'Canada', 'Japan'], 'Physical_Form': ['Green Beans', 'Extract', 'Ground'], 'Processing_Method': ['Washed', 'Semi-washed', 'Natural', 'Steamed', 'Dry Mill', 'Eco Pulped', 'Wet Hulled', 'Unwashed', 'Honey Process', 'Dried', 'Wet Processed', 'Polished', 'Roasted', 'Wet Polished', 'Dry Processed'], 'Quality_Grade': ['Aa', 'Grade 1', 'SHG', 'SHG EP', 'HG EP', 'Fine Cup', 'Grade 2/3', 'Strictly Soft', 'Grade B', 'Grade 2', 'NY2/3', 'AAA', 'Excelso EP', 'Extra Prima', 'Grade U', 'Grade', 'Supremo', 'EP', 'SHB', 'FAQ', 'Excelso', 'European Preparation', 'AB3', 'AB', 'Type A', 'Grade 5/6', 'Grade 5', 'A', 'Grade 4', 'AAA/AA/AB', 'Grade A', 'Triage', 'Grade 3', 'Gr 1', 'Grade 12', 'HG', 'SHB EP', '17 A', 'FC', 'Standard', 'Premier', 'Premium', 'AB+', 'Excelso AB', 'Grade AAA', 'Low Grade', 'Super Grade', 'HB', 'HB EP Grade 2', 'Class 24', 'OESHG', 'Grade AA', 'Grade AB', 'Grade I', 'Grade 16', 'Good Cup', 'AA-AB', 'GC 13UP', 'GC 14', 'Standard A18WLAOS', 'Specialty Grade', 'Graded', 'Prime', 'Type 1', 'NY2', 'GF-27', 'GF266 16', 'GF268 12', 'GF268 13', 'GF268 20', 'GF269 57', 'Organic', 'DDQ', 'European Quality', 'A+', 'SCR 15', 'A Grade I', 'C', 'High', 'HB EP', 'Commercial', 'Imperfecto', 'Top Quality', 'Plantation A', 'Commercial 2', 'NY4/5', 'SSFC', 'A Grade', 'Type 2', 'Premium Grade 1', 'Top Class', 'Type I', 'Grade B1', 'Grade B2', 'Grade C'], 'Screen_Size': ['Screen 17', 'Screen 15+', 'Screen 14', 'Screen 14/15/16', 'Screen 14/16', 'Screen 15/16', 'Screen 16', 'Screen 14/15', 'Screen 17/18', 'Screen 16+', 'Screen 13', 'Screen 18', 'Screen', 'Screen 12', 'Screen 15', 'Screen 12/14', 'Screen 4/5', 'Screen 13+', 'Screen 9/11', 'Screen 16/17/18', 'Screen 16/18', 'Screen 1', 'Screen 18+', 'Screen 14+', 'EP', 'Screen 20', 'Screen 17+']}}\n",
      "\n",
      "Schema:\n",
      "product_id (STRING)\n",
      "product_name (STRING)\n",
      "synonymns (STRING)\n",
      "product_schema (JSON)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "#  Fetch one row\n",
    "query = \"SELECT * FROM `dev-tradyon-data.tradyon.product_master` LIMIT 1\"\n",
    "rows = client.query_and_wait(query)\n",
    "for row in rows:\n",
    "    sample_row = dict(row)\n",
    "    print(\"Sample row:\", sample_row)\n",
    "\n",
    "# 2️ Fetch schema directly from table object\n",
    "table = client.get_table(\"dev-tradyon-data.tradyon.product_master\")\n",
    "print(\"\\nSchema:\")\n",
    "for field in table.schema:\n",
    "    print(f\"{field.name} ({field.field_type})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9374a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample row: {'date': datetime.datetime(2022, 12, 9, 0, 0), 'hs_code': '090411', 'goods_shipped': None, 'shipment_destination': 'United States', 'shipment_origin': 'Hong Kong', 'port_of_lading': 'Hong Kong, Hong Kong', 'port_of_lading_country': 'Hong Kong', 'port_of_lading_un_locode': None, 'port_of_unlading': 'Port Of Entry-Miami Seaport, Miami, Florida', 'port_of_unlading_country': None, 'port_of_unlading_un_locode': None, 'trade_direction': 'Import', 'transport_method': 'Maritime', 'is_containerized': '1.0', 'value_of_goods_usd': 3100.0, 'industry_gics': '30202030', 'shipment_id': '33b54e4a6e15a3c8a1d12615868ecb5f18c0b195bbf582a132e3fc31e42a4580', 'is_multi_product_shipment': False, 'volume_teu': None, 'weight_in_kg': 625.0, 'shipper_profile': None, 'shipper_ultimate_parent_profile': None, 'consignee_profile': None, 'consignee_ultimate_parent_profile': None, 'consignee_tradyon_profile_id': None, 'shipper_tradyon_profile_id': None, 'consignee_business_id': None, 'shipper_business_id': None, 'unit_price': 4.96, 'original_consignee_business_id': None, 'original_shipper_business_id': None, 'product_id': None, 'product_name': None, 'attributes': None, 'attributes_struct': None, 'is_outlier': None, 'outlier_type': None}\n",
      "\n",
      "Schema:\n",
      "date (DATETIME)\n",
      "hs_code (STRING)\n",
      "goods_shipped (STRING)\n",
      "shipment_destination (STRING)\n",
      "shipment_origin (STRING)\n",
      "port_of_lading (STRING)\n",
      "port_of_lading_country (STRING)\n",
      "port_of_lading_un_locode (STRING)\n",
      "port_of_unlading (STRING)\n",
      "port_of_unlading_country (STRING)\n",
      "port_of_unlading_un_locode (STRING)\n",
      "trade_direction (STRING)\n",
      "transport_method (STRING)\n",
      "is_containerized (STRING)\n",
      "value_of_goods_usd (FLOAT)\n",
      "industry_gics (STRING)\n",
      "shipment_id (STRING)\n",
      "is_multi_product_shipment (BOOLEAN)\n",
      "volume_teu (FLOAT)\n",
      "weight_in_kg (FLOAT)\n",
      "shipper_profile (STRING)\n",
      "shipper_ultimate_parent_profile (STRING)\n",
      "consignee_profile (STRING)\n",
      "consignee_ultimate_parent_profile (STRING)\n",
      "consignee_tradyon_profile_id (INTEGER)\n",
      "shipper_tradyon_profile_id (INTEGER)\n",
      "consignee_business_id (STRING)\n",
      "shipper_business_id (STRING)\n",
      "unit_price (FLOAT)\n",
      "original_consignee_business_id (STRING)\n",
      "original_shipper_business_id (STRING)\n",
      "product_id (STRING)\n",
      "product_name (STRING)\n",
      "attributes (JSON)\n",
      "attributes_struct (RECORD)\n",
      "is_outlier (BOOLEAN)\n",
      "outlier_type (STRING)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# 1️ Fetch one row\n",
    "query = \"SELECT * FROM `dev-tradyon-data.tradyon.shipment_master_taxonomy` LIMIT 1\"\n",
    "rows = client.query_and_wait(query)\n",
    "for row in rows:\n",
    "    sample_row = dict(row)\n",
    "    print(\"Sample row:\", sample_row)\n",
    "\n",
    "# 2️ Fetch schema directly from table object\n",
    "table = client.get_table(\"dev-tradyon-data.tradyon.shipment_master_taxonomy\")\n",
    "print(\"\\nSchema:\")\n",
    "for field in table.schema:\n",
    "    print(f\"{field.name} ({field.field_type})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c6ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 35365 rows to dev-tradyon-data.tradyon.shipment_master_taxonomy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.cloud import bigquery\n",
    "import csv\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "csv_path = '/home/parshav-potato/Work/tradyon/generic_pipeline/rice.csv'\n",
    "\n",
    "data = []\n",
    "with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        cleaned = {k: (v if v != '' else None) for k, v in row.items()}\n",
    "        if cleaned.get('is_multi_product_shipment') is not None:\n",
    "            cleaned['is_multi_product_shipment'] = cleaned['is_multi_product_shipment'].lower() == 'true'\n",
    "        # Drop attributes_struct if present so schema matches table definition\n",
    "        cleaned.pop('attributes_struct', None)\n",
    "        data.append(cleaned)\n",
    "\n",
    "if not data:\n",
    "    raise ValueError('No rows found in sample_onion.csv')\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField('date', 'DATETIME'),\n",
    "    bigquery.SchemaField('hs_code', 'STRING'),\n",
    "    bigquery.SchemaField('goods_shipped', 'STRING'),\n",
    "    bigquery.SchemaField('shipment_destination', 'STRING'),\n",
    "    bigquery.SchemaField('shipment_origin', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_lading', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_lading_country', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_lading_un_locode', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_unlading', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_unlading_country', 'STRING'),\n",
    "    bigquery.SchemaField('port_of_unlading_un_locode', 'STRING'),\n",
    "    bigquery.SchemaField('trade_direction', 'STRING'),\n",
    "    bigquery.SchemaField('transport_method', 'STRING'),\n",
    "    bigquery.SchemaField('is_containerized', 'STRING'),\n",
    "    bigquery.SchemaField('value_of_goods_usd', 'FLOAT'),\n",
    "    bigquery.SchemaField('industry_gics', 'STRING'),\n",
    "    bigquery.SchemaField('shipment_id', 'STRING'),\n",
    "    bigquery.SchemaField('is_multi_product_shipment', 'BOOLEAN'),\n",
    "    bigquery.SchemaField('volume_teu', 'FLOAT'),\n",
    "    bigquery.SchemaField('weight_in_kg', 'FLOAT'),\n",
    "    bigquery.SchemaField('shipper_profile', 'STRING'),\n",
    "    bigquery.SchemaField('shipper_ultimate_parent_profile', 'STRING'),\n",
    "    bigquery.SchemaField('consignee_profile', 'STRING'),\n",
    "    bigquery.SchemaField('consignee_ultimate_parent_profile', 'STRING'),\n",
    "    bigquery.SchemaField('consignee_tradyon_profile_id', 'INTEGER'),\n",
    "    bigquery.SchemaField('shipper_tradyon_profile_id', 'INTEGER'),\n",
    "    bigquery.SchemaField('consignee_business_id', 'STRING'),\n",
    "    bigquery.SchemaField('shipper_business_id', 'STRING'),\n",
    "    bigquery.SchemaField('unit_price', 'FLOAT'),\n",
    "    bigquery.SchemaField('original_consignee_business_id', 'STRING'),\n",
    "    bigquery.SchemaField('original_shipper_business_id', 'STRING'),\n",
    "    bigquery.SchemaField('product_id', 'STRING'),\n",
    "    bigquery.SchemaField('product_name', 'STRING'),\n",
    "    bigquery.SchemaField('attributes', 'JSON'),\n",
    "    bigquery.SchemaField('is_outlier', 'BOOLEAN'),\n",
    "    bigquery.SchemaField('outlier_type', 'STRING'),\n",
    "]\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "table_id = 'dev-tradyon-data.tradyon.shipment_master_taxonomy'\n",
    "\n",
    "job = client.load_table_from_json(data, table_id, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f'Appended {len(data)} rows to {table_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ca5ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/parshav-potato/Work/tradyon/generic_pipeline/output/onion/per_product_classifications/output/rice_1006/shipment_id_to_attr.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Read CSV and aggregate by shipment_id\u001b[39;00m\n\u001b[32m     10\u001b[39m csv_updates = {}\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     12\u001b[39m     reader = csv.DictReader(f)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/tradyon/generic_pipeline/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/parshav-potato/Work/tradyon/generic_pipeline/output/onion/per_product_classifications/output/rice_1006/shipment_id_to_attr.csv'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import csv\n",
    "import json\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "csv_path = '/home/parshav-potato/Work/tradyon/generic_pipeline/output/onion/per_product_classifications/output/rice_1006/shipment_id_to_attr.csv'\n",
    "\n",
    "# Read CSV and aggregate by shipment_id\n",
    "csv_updates = {}\n",
    "with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        shipment_id = (row.get('shipment_id') or '').strip()\n",
    "        if not shipment_id:\n",
    "            continue\n",
    "        \n",
    "        raw_product = (row.get('product') or '').strip()\n",
    "        product_name = raw_product if raw_product and raw_product.lower() != 'none' else None\n",
    "        \n",
    "        attrs_raw = (row.get('attrs_json') or '').strip()\n",
    "        attrs = json.loads(attrs_raw) if attrs_raw else None\n",
    "        \n",
    "        # Initialize or get existing entry\n",
    "        existing = csv_updates.setdefault(shipment_id, {\n",
    "            'shipment_id': shipment_id,\n",
    "            'product_name': None,\n",
    "            'attributes': {}\n",
    "        })\n",
    "        \n",
    "        # Update product_name if not already set\n",
    "        if product_name and not existing['product_name']:\n",
    "            existing['product_name'] = product_name\n",
    "        \n",
    "        # Merge attributes\n",
    "        if attrs:\n",
    "            existing['attributes'].update(attrs)\n",
    "\n",
    "# Filter to only rows with actual data\n",
    "csv_updates = {k: v for k, v in csv_updates.items() if v['product_name'] or v['attributes']}\n",
    "\n",
    "if not csv_updates:\n",
    "    raise ValueError('No applicable shipment rows found to update.')\n",
    "\n",
    "print(f'Found {len(csv_updates)} shipment IDs to update from CSV')\n",
    "\n",
    "# Fetch existing data from BigQuery for these shipment IDs\n",
    "shipment_ids = list(csv_updates.keys())\n",
    "batch_size = 1000\n",
    "existing_data = {}\n",
    "\n",
    "for i in range(0, len(shipment_ids), batch_size):\n",
    "    batch = shipment_ids[i:i + batch_size]\n",
    "    ids_str = ', '.join([f\"'{sid}'\" for sid in batch])\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT shipment_id, product_name, attributes\n",
    "    FROM `dev-tradyon-data.tradyon.shipment_master_taxonomy`\n",
    "    WHERE shipment_id IN ({ids_str})\n",
    "    \"\"\"\n",
    "    \n",
    "    results = client.query(query).result()\n",
    "    for row in results:\n",
    "        existing_data[row.shipment_id] = {\n",
    "            'product_name': row.product_name,\n",
    "            'attributes': dict(row.attributes) if row.attributes else {}\n",
    "        }\n",
    "\n",
    "print(f'Fetched {len(existing_data)} existing records from BigQuery')\n",
    "\n",
    "# Merge CSV data with existing data\n",
    "final_updates = []\n",
    "for shipment_id, csv_data in csv_updates.items():\n",
    "    existing = existing_data.get(shipment_id, {'product_name': None, 'attributes': {}})\n",
    "    \n",
    "    # Merge attributes (CSV data takes precedence)\n",
    "    merged_attributes = dict(existing['attributes'])\n",
    "    merged_attributes.update(csv_data['attributes'])\n",
    "    \n",
    "    final_updates.append({\n",
    "        'shipment_id': shipment_id,\n",
    "        'product_name': csv_data['product_name'] or existing['product_name'],\n",
    "        'attributes': merged_attributes if merged_attributes else None\n",
    "    })\n",
    "\n",
    "# Create temporary table with merged updates\n",
    "temp_table_id = 'dev-tradyon-data.tradyon._shipment_attr_updates'\n",
    "\n",
    "load_job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    schema=[\n",
    "        bigquery.SchemaField('shipment_id', 'STRING'),\n",
    "        bigquery.SchemaField('product_name', 'STRING'),\n",
    "        bigquery.SchemaField('attributes', 'JSON'),\n",
    "    ],\n",
    ")\n",
    "\n",
    "load_job = client.load_table_from_json(final_updates, temp_table_id, job_config=load_job_config)\n",
    "load_job.result()\n",
    "\n",
    "# Merge updates into main table\n",
    "merge_query = \"\"\"\n",
    "MERGE `dev-tradyon-data.tradyon.shipment_master_taxonomy` T\n",
    "USING `dev-tradyon-data.tradyon._shipment_attr_updates` S\n",
    "ON T.shipment_id = S.shipment_id\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    product_name = S.product_name,\n",
    "    attributes = S.attributes\n",
    "\"\"\"\n",
    "\n",
    "merge_result = client.query(merge_query).result()\n",
    "\n",
    "# Clean up temporary table\n",
    "client.delete_table(temp_table_id, not_found_ok=True)\n",
    "\n",
    "print(f'Successfully updated {len(final_updates)} shipment records in BigQuery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f48779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted temporary table: dev-tradyon-data.tradyon._shipment_attr_updates\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Delete temporary table\n",
    "temp_table_id = 'dev-tradyon-data.tradyon._shipment_attr_updates'\n",
    "\n",
    "try:\n",
    "    client.delete_table(temp_table_id, not_found_ok=True)\n",
    "    print(f'Deleted temporary table: {temp_table_id}')\n",
    "except Exception as e:\n",
    "    print(f'Error deleting table: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99385ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dca002f",
   "metadata": {},
   "source": [
    "## Load product schema master\n",
    "Appends rows from `output/product_schema_master.csv` into `tradyon.product_master` with normalized schema keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7808de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 1 rows to dev-tradyon-data.tradyon.product_master\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import csv\n",
    "import json\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "csv_path = '/home/parshav-potato/Work/tradyon/generic_pipeline/output/onion/product_schema_master.csv'\n",
    "\n",
    "records = []\n",
    "with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        raw_schema = json.loads(row['schema_json'])\n",
    "        # Normalize keys to Title_Case with underscores for consistency\n",
    "        normalized_schema = {\n",
    "            '_'.join(part.capitalize() for part in key.split('_')): value\n",
    "            for key, value in raw_schema.items()\n",
    "        }\n",
    "        records.append({\n",
    "            'product_id': row['product_id'],\n",
    "            'product_name': row['product'],\n",
    "            'synonymns': '',\n",
    "            'product_schema': normalized_schema\n",
    "        })\n",
    "\n",
    "if not records:\n",
    "    raise ValueError('No rows found in product_schema_master.csv to append.')\n",
    "\n",
    "table_id = 'dev-tradyon-data.tradyon.product_master'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    "    schema=[\n",
    "        bigquery.SchemaField('product_id', 'STRING'),\n",
    "        bigquery.SchemaField('product_name', 'STRING'),\n",
    "        bigquery.SchemaField('synonymns', 'STRING'),\n",
    "        bigquery.SchemaField('product_schema', 'JSON'),\n",
    "    ],\n",
    ")\n",
    "\n",
    "job = client.load_table_from_json(records, table_id, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f'Appended {len(records)} rows to {table_id}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
